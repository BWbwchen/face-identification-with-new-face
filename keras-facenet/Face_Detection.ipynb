{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/bwbwchen/.local/lib/python3.6/site-packages (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-image in /home/bwbwchen/.local/lib/python3.6/site-packages (0.17.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /home/bwbwchen/.local/lib/python3.6/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/bwbwchen/.local/lib/python3.6/site-packages (from scikit-image) (2020.9.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/bwbwchen/.local/lib/python3.6/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /home/bwbwchen/.local/lib/python3.6/site-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/bwbwchen/.local/lib/python3.6/site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/bwbwchen/.local/lib/python3.6/site-packages (from scikit-image) (7.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/bwbwchen/.local/lib/python3.6/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/bwbwchen/.local/lib/python3.6/site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/bwbwchen/.local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/bwbwchen/.local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/bwbwchen/.local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/bwbwchen/.local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/bwbwchen/.local/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/bwbwchen/.local/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (46.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /home/bwbwchen/.local/lib/python3.6/site-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/bwbwchen/.local/lib/python3.6/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /home/bwbwchen/.local/lib/python3.6/site-packages (from keras) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from keras) (3.12)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/bwbwchen/.local/lib/python3.6/site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /home/bwbwchen/.local/lib/python3.6/site-packages (from h5py->keras) (1.5.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)\n",
      "\u001b[K     |################################| 394.7 MB 3.7 kB/s ta 0:00:0101     |#################               | 214.0 MB 10.5 MB/s eta 0:00:18     |############################    | 356.1 MB 12.2 MB/s eta 0:00:04\n",
      "\u001b[?25hProcessing /home/bwbwchen/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc/termcolor-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/bwbwchen/.local/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting h5py~=2.10.0\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Using cached grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/bwbwchen/.local/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/bwbwchen/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (46.1.3)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.6.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2018.1.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.22)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.6)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.1)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: termcolor, six, keras-preprocessing, flatbuffers, google-pasta, wheel, astunparse, markdown, cachetools, rsa, google-auth, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, werkzeug, absl-py, grpcio, protobuf, tensorboard-plugin-wit, tensorboard, h5py, typing-extensions, gast, tensorflow-estimator, opt-einsum, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.3 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.6 six-1.15.0 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-1.0.1 wheel-0.36.2\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install scikit-image\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cS5Ysiq5wYUc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import signal\n",
    "from IPython import display\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.transform import resize\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8r5-rEMqwdtR"
   },
   "outputs": [],
   "source": [
    "cascade_path = 'haarcascades/haarcascade_frontalface_default.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Th-wKvKCw5fa",
    "outputId": "95c45228-d9a0-4294-a651-da5fc193ef4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model/facenet_keras.h5'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "330bl9evxdnJ"
   },
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pc8RfYpbxo7H"
   },
   "outputs": [],
   "source": [
    "def calc_embs(imgs, margin, batch_size):\n",
    "    aligned_images = prewhiten(imgs)\n",
    "    pd = []\n",
    "    for start in range(0, len(aligned_images), batch_size):\n",
    "        pd.append(model.predict_on_batch(aligned_images[start:start+batch_size]))\n",
    "    embs = l2_normalize(np.concatenate(pd))\n",
    "\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NIbSqwfnxrr1"
   },
   "outputs": [],
   "source": [
    "class FaceDemo(object):\n",
    "    def __init__(self, cascade_path):\n",
    "        self.vc = None\n",
    "        self.cascade = cv2.CascadeClassifier(cascade_path)\n",
    "        self.margin = 10\n",
    "        self.batch_size = 1\n",
    "        self.n_img_per_person = 10\n",
    "        self.is_interrupted = False\n",
    "        self.data = {}\n",
    "        self.le = None\n",
    "        self.clf = None\n",
    "        \n",
    "    def _signal_handler(self, signal, frame):\n",
    "        self.is_interrupted = True\n",
    "        \n",
    "    def capture_images(self, name='Unknown'):\n",
    "        vc = cv2.VideoCapture(0)\n",
    "        self.vc = vc\n",
    "        if vc.isOpened():\n",
    "            is_capturing, _ = vc.read()\n",
    "        else:\n",
    "            is_capturing = False\n",
    "\n",
    "        imgs = []\n",
    "        signal.signal(signal.SIGINT, self._signal_handler)\n",
    "        self.is_interrupted = False\n",
    "        while is_capturing:\n",
    "            is_capturing, frame = vc.read()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            faces = self.cascade.detectMultiScale(frame,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=3,\n",
    "                                         minSize=(100, 100))\n",
    "            if len(faces) != 0:\n",
    "                face = faces[0]\n",
    "                (x, y, w, h) = face\n",
    "                left = x - self.margin // 2\n",
    "                right = x + w + self.margin // 2\n",
    "                bottom = y - self.margin // 2\n",
    "                top = y + h + self.margin // 2\n",
    "                img = resize(frame[bottom:top, left:right, :],\n",
    "                             (160, 160), mode='reflect')\n",
    "                imgs.append(img)\n",
    "                cv2.rectangle(frame,\n",
    "                              (left-1, bottom-1),\n",
    "                              (right+1, top+1),\n",
    "                              (255, 0, 0), thickness=2)\n",
    "\n",
    "            plt.imshow(frame)\n",
    "            plt.title('{}/{}'.format(len(imgs), self.n_img_per_person))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            display.clear_output(wait=True)\n",
    "            if len(imgs) == self.n_img_per_person:\n",
    "                vc.release()\n",
    "                self.data[name] = np.array(imgs)\n",
    "                break\n",
    "            try:\n",
    "                plt.pause(0.1)\n",
    "            except Exception:\n",
    "                pass\n",
    "            if self.is_interrupted:\n",
    "                vc.release()\n",
    "                break\n",
    "                \n",
    "    def train(self):\n",
    "        labels = []\n",
    "        embs = []\n",
    "        names = self.data.keys()\n",
    "        for name, imgs in self.data.items():\n",
    "            embs_ = calc_embs(imgs, self.margin, self.batch_size)    \n",
    "            labels.extend([name] * len(embs_))\n",
    "            embs.append(embs_)\n",
    "\n",
    "        embs = np.concatenate(embs)\n",
    "        le = LabelEncoder().fit(labels)\n",
    "        y = le.transform(labels)\n",
    "        clf = SVC(kernel='linear', probability=True).fit(embs, y)\n",
    "        \n",
    "        self.le = le\n",
    "        self.clf = clf\n",
    "        \n",
    "    def infer(self):\n",
    "        vc = cv2.VideoCapture(0)\n",
    "        self.vc = vc\n",
    "        if vc.isOpened():\n",
    "            is_capturing, _ = vc.read()\n",
    "        else:\n",
    "            is_capturing = False\n",
    "\n",
    "        signal.signal(signal.SIGINT, self._signal_handler)\n",
    "        self.is_interrupted = False\n",
    "        while is_capturing:\n",
    "            is_capturing, frame = vc.read()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            faces = self.cascade.detectMultiScale(frame,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=3,\n",
    "                                         minSize=(100, 100))\n",
    "            pred = None\n",
    "            if len(faces) != 0:\n",
    "                for faceid, (x, y, w, h) in enumerate(faces) :\n",
    "                    left = x - self.margin // 2\n",
    "                    right = x + w + self.margin // 2\n",
    "                    bottom = y - self.margin // 2\n",
    "                    top = y + h + self.margin // 2\n",
    "                    img = resize(frame[bottom:top, left:right, :],\n",
    "                                 (160, 160), mode='reflect')\n",
    "                    embs = calc_embs(img[np.newaxis], self.margin, 1)\n",
    "                    pred = self.le.inverse_transform(self.clf.predict(embs))\n",
    "                    cv2.rectangle(frame,\n",
    "                                  (left-1, bottom-1),\n",
    "                                  (right+1, top+1),\n",
    "                                  (255, 0, 0), thickness=2)\n",
    "            plt.imshow(frame)\n",
    "            plt.title(pred)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            display.clear_output(wait=True)\n",
    "            try:\n",
    "                plt.pause(0.1)\n",
    "            except Exception:\n",
    "                pass\n",
    "            if self.is_interrupted:\n",
    "                vc.release()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ff7P43ZAx06F"
   },
   "outputs": [],
   "source": [
    "f = FaceDemo(cascade_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XQ9PyaAwx3N8"
   },
   "outputs": [],
   "source": [
    "# Train with two or more people\n",
    "f.capture_images('ivan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with two or more people\n",
    "f.capture_images('park seo joon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "Wd6L_skvx6ea",
    "outputId": "a9716ba9-0284-4e41-995a-4cc13ed17326"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-770cb541f283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-720c27c39f20>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0membs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "f.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FToC3egQx8N2"
   },
   "outputs": [],
   "source": [
    "f.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test point 1\n",
      "Test point 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"Test point 1\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Test point 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Face Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
